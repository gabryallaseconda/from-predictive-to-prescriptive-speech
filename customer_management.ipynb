{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Management Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrative\n",
    "\n",
    "\n",
    "Your company has grouped customers into three classes, active customers, semi-active customers and inactive customers. In each time period the company earns something from each active customer, less from semi-active customers. In each time period, the company can do some customer marketing that can move some customers from one status to another, but this has a cost. What is the best action?\n",
    "\n",
    "- Email Marketing: to all customers, bad and good effects\n",
    "- Coupon: to semi-active and non-active, some improvements but some active becomes non-active\n",
    "- Resurrection: to non-active, many non-active becomes active or semi-active, but with little drawbaks\n",
    "- Special: only little improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ_params = {\n",
    "    'reward_per_active' : 15,\n",
    "    'reward_per_semi_active' : 10,\n",
    "    \n",
    "    'action_email_cost' : 3,\n",
    "    'action_coupon_cost' : 20,\n",
    "    'action_resurrection_cost' : 15,\n",
    "    'action_special_cost' : 16,\n",
    "\n",
    "    'epoch_new_active' : 10,\n",
    "    'epoch_new_semi_active' : 5,\n",
    "    'epoch_active_to_semi_active': (.02, .001),\n",
    "    'epoch_semi_active_to_non_active': (.05, .002),\n",
    "    \n",
    "    'email_semi_active_to_active' : (.1, .005),\n",
    "    'email_non_active_to_active' : (.15, .02),\n",
    "    'email_non_active_to_semi_active' : (.1, .02),\n",
    "    'email_2_active_to_non_active': (.05, .005),\n",
    "    'email_2_active_to_semi_active' : (.05, .005),\n",
    "    'email_2_semi_active_to_non_active' : (.1 , .02),\n",
    "    \n",
    "    'coupon_semi_active_to_active' : (.5, .02),\n",
    "    'coupon_non_active_to_active' : (.2, .005),\n",
    "    'coupon_active_to_non_active' : (.02, .001),\n",
    "    \n",
    "    'resurrection_non_active_to_active' : (.4, .02),\n",
    "    'resurrection_non_active_to_semi_active' : (.1, .015),\n",
    "    'resurrection_active_to_semi_active' : (.05, .005),\n",
    "    'resurrection_semi_active_to_non_active' : (.05, .005),\n",
    "\n",
    "    'special_semi_active_to_active' : (.1, .005),\n",
    "    'special_non_active_to_semi_active' : (.05, .005),\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def customer_transition(source_number, params):\n",
    "    loc, scale = params\n",
    "    # Sample from Normal random variable\n",
    "    transation = np.random.normal(loc, scale, 1)[0]\n",
    "    # Make sample a proportion\n",
    "    transation = max( min(1,transation), 0)\n",
    "    # Find the number of transiting customers\n",
    "    transation *= source_number\n",
    "    # Cast into int\n",
    "    transation = int(transation)\n",
    "\n",
    "    return transation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Environment():\n",
    "\n",
    "    def __init__(self, active_customers, semi_active_customers, non_active_customers):\n",
    "        self._active_customers = active_customers\n",
    "        self._semi_active_customers = semi_active_customers\n",
    "        self._non_active_customers = non_active_customers\n",
    "\n",
    "        self._active_customers_final = 0\n",
    "        self._semi_active_customers_final = 0\n",
    "        self._non_active_customers_final = 0\n",
    "\n",
    "        #self._active_customers_next_transitions = 0\n",
    "        #self._semi_active_customers_next_transitions = 0\n",
    "        #self._non_active_customers_next_transitions = 0\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Active: \\t {self._active_customers}\\nSemi act: \\t {self._semi_active_customers}\\nNon act \\t {self._non_active_customers}\\n\"\n",
    "\n",
    "\n",
    "    # Good transitions\n",
    "        \n",
    "    def _semi_active_to_active(self, param):\n",
    "        number = customer_transition(self._semi_active_customers, param)\n",
    "        self._semi_active_customers_final -= number\n",
    "        self._active_customers_final += number\n",
    "\n",
    "    def _non_active_to_active(self, param):\n",
    "        number = customer_transition(self._non_active_customers, param)\n",
    "        self._non_active_customers_final -= number\n",
    "        self._active_customers_final += number\n",
    "\n",
    "    def _non_active_to_semi_active(self, param):\n",
    "        number = customer_transition(self._non_active_customers, param)\n",
    "        self._non_active_customers_final -= number\n",
    "        self._semi_active_customers_final += number\n",
    "\n",
    "\n",
    "    # Bad transitions\n",
    "        \n",
    "    def _active_to_semi_active(self, param):\n",
    "        number = customer_transition(self._active_customers, param)\n",
    "        self._active_customers_final -= number\n",
    "        self._semi_active_customers_final += number\n",
    "        \n",
    "    def _active_to_non_active(self, param):\n",
    "        number = customer_transition(self._active_customers, param)\n",
    "        self._active_customers_final -= number\n",
    "        self._non_active_customers_final += number\n",
    "\n",
    "    def _semi_active_to_non_active(self, param):\n",
    "        number = customer_transition(self._semi_active_customers, param)\n",
    "        self._semi_active_customers_final -= number\n",
    "        self._non_active_customers_final += number\n",
    "\n",
    "\n",
    "    # Actions    \n",
    "        \n",
    "    def _step_organic(self):\n",
    "        self._active_to_semi_active(environ_params.get('epoch_active_to_semi_active'))\n",
    "        self._semi_active_to_non_active(environ_params.get('epoch_semi_active_to_non_active'))\n",
    "\n",
    "    def _action_email(self):\n",
    "        self._semi_active_to_active(environ_params.get('email_semi_active_to_active'))\n",
    "        self._non_active_to_active(environ_params.get('email_non_active_to_active'))\n",
    "        self._non_active_to_semi_active(environ_params.get('email_non_active_to_semi_active'))\n",
    "\n",
    "        # Should be 2 step ahead\n",
    "        self._active_to_non_active(environ_params.get('email_2_active_to_non_active'))\n",
    "        self._active_to_semi_active(environ_params.get('email_2_active_to_semi_active'))\n",
    "        self._semi_active_to_non_active(environ_params.get('email_2_semi_active_to_non_active'))\n",
    "\n",
    "\n",
    "    def _action_coupon(self):\n",
    "        self._semi_active_to_active(environ_params.get('coupon_semi_active_to_active'))\n",
    "        self._non_active_to_active(environ_params.get('coupon_non_active_to_active'))\n",
    "        self._active_to_non_active(environ_params.get('coupon_active_to_non_active'))\n",
    "\n",
    "    def _action_resurrection(self):\n",
    "        self._non_active_to_active(environ_params.get('resurrection_non_active_to_active'))\n",
    "        self._non_active_to_semi_active(environ_params.get('resurrection_non_active_to_semi_active'))\n",
    "        self._active_to_semi_active(environ_params.get('resurrection_active_to_semi_active'))\n",
    "        self._semi_active_to_non_active(environ_params.get('resurrection_semi_active_to_non_active'))\n",
    "\n",
    "    def _action_special(self):\n",
    "        self._semi_active_to_active(environ_params.get('special_semi_active_to_active'))\n",
    "        self._non_active_to_semi_active(environ_params.get('special_non_active_to_semi_active'))\n",
    "\n",
    "\n",
    "    # State transition\n",
    "        \n",
    "    def step(self, action : str = None):\n",
    "\n",
    "        # New organic customers\n",
    "        self._active_customers += environ_params.get('epoch_new_active')\n",
    "        self._semi_active_customers += environ_params.get('epoch_new_semi_active')\n",
    "        \n",
    "    \n",
    "        # Setup the customers classes after the action\n",
    "        self._active_customers_final = self._active_customers\n",
    "        self._semi_active_customers_final = self._semi_active_customers\n",
    "        self._non_active_customers_final = self._non_active_customers\n",
    "\n",
    "        # Do step organic transitions\n",
    "        self._step_organic()\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self._active_customers * environ_params.get('reward_per_active') + \\\n",
    "                 self._semi_active_customers * environ_params.get('reward_per_semi_active')\n",
    "\n",
    "        # Do action and update the costs\n",
    "        if action == 'email':\n",
    "            self._action_email()\n",
    "            reward -= (self._active_customers + self._semi_active_customers + self._non_active_customers) * environ_params.get('action_email_cost')\n",
    "        elif action == 'coupon':\n",
    "            self._action_coupon()\n",
    "            reward -= (self._semi_active_customers + self._non_active_customers) * environ_params.get('action_coupon_cost')\n",
    "        elif action == 'resurrection':\n",
    "            self._action_resurrection()\n",
    "            reward -= (self._non_active_customers) * environ_params.get('action_resurrection_cost')\n",
    "        elif action == 'special':\n",
    "            self._action_special()\n",
    "            reward -= (self._active_customers + self._semi_active_customers + self._non_active_customers) * environ_params.get('action_special_cost')\n",
    "\n",
    "        # Update customer classes\n",
    "        self._active_customers = max(0, self._active_customers_final)\n",
    "        self._semi_active_customers = max(0, self._semi_active_customers_final)\n",
    "        self._non_active_customers = max(0, self._non_active_customers_final)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def make_step(self, action : str = None):\n",
    "        print(f\"Reward: \\t {self.step(action)}\\n - \\n\")\n",
    "\n",
    "\n",
    "    # For VFA\n",
    "\n",
    "    def export_status(self):\n",
    "        return (self._active_customers, self._semi_active_customers, self._non_active_customers)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_environment = Environment(active_customers=1500, semi_active_customers=1200, non_active_customers=2300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: \t 1500\n",
      "Semi act: \t 1200\n",
      "Non act \t 2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: \t 34700\n",
      " - \n",
      "\n",
      "Active: \t 1480\n",
      "Semi act: \t 1176\n",
      "Non act \t 2359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_environment.make_step()\n",
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: \t 34160\n",
      " - \n",
      "\n",
      "Active: \t 1462\n",
      "Semi act: \t 1150\n",
      "Non act \t 2418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_environment.make_step()\n",
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: \t 18495\n",
      " - \n",
      "\n",
      "Active: \t 1810\n",
      "Semi act: \t 1179\n",
      "Non act \t 2056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_environment.make_step('email')\n",
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: \t 39140\n",
      " - \n",
      "\n",
      "Active: \t 1787\n",
      "Semi act: \t 1160\n",
      "Non act \t 2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_environment.make_step()\n",
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: \t -42595\n",
      " - \n",
      "\n",
      "Active: \t 1884\n",
      "Semi act: \t 1130\n",
      "Non act \t 2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_environment.make_step('special')\n",
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: \t 39760\n",
      " - \n",
      "\n",
      "Active: \t 1857\n",
      "Semi act: \t 1115\n",
      "Non act \t 2118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_environment.make_step()\n",
    "print(my_environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Function Approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VFA_Agent():\n",
    "\n",
    "    def __init__(self, actions, gamma, alpha, epsilon):\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon # Exploration-exploitation balance parameter\n",
    "\n",
    "        self._actions = actions\n",
    "        self._actions_dim = len(actions)\n",
    "\n",
    "        self._state = (0, 0, 0)\n",
    "\n",
    "        self._tile_coding_coef = 100\n",
    "\n",
    "        self._state_active_dim = 100\n",
    "        self._state_semi_active_dim = 100\n",
    "        self._state_non_active_dim = 100\n",
    "\n",
    "        self._q_function = np.zeros([self._state_active_dim, self._state_semi_active_dim, self._state_non_active_dim, self._actions_dim])\n",
    "\n",
    "\n",
    "    def _tile_coding(self, export):\n",
    "        (num_active, num_semi_active, num_non_active) = export\n",
    "        return (int(num_active/self._tile_coding_coef), \n",
    "                       int(num_semi_active/self._tile_coding_coef), \n",
    "                       int(num_non_active/self._tile_coding_coef))\n",
    "\n",
    "\n",
    "    def _set_state(self, export):\n",
    "        self._state = self._tile_coding(export)\n",
    "\n",
    "        \n",
    "    def _select_action(self):\n",
    "        \"\"\"\n",
    "        Select best action considering exploration-exploitation balance\n",
    "        \"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randint(0, self._actions_dim - 1)\n",
    "        else:\n",
    "            q_values = [self._q_function[self._state + (a,)] for a in range(self._actions_dim)]\n",
    "            # Break the ties!\n",
    "            best_actions = np.where(q_values == np.max(q_values))[0]\n",
    "            return np.random.choice(best_actions)\n",
    "        \n",
    "    def _update_q_function(self, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Q-Learning core: this fuction calculates the update of the q function\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the current value of the q function for the given state and action \n",
    "        current_q = self._q_function[self._state + (action,)]\n",
    "        \n",
    "        # get the q function value for the prescribed action for the next state\n",
    "        max_next_q = np.max(self._q_function[next_state])\n",
    "\n",
    "        # calculate the temporal difference  (Q - learning)\n",
    "        td_error = reward + self.gamma * max_next_q - current_q\n",
    "\n",
    "        # update the q function (Q - learning)\n",
    "        self._q_function[self._state + (action,)] += self.alpha * td_error\n",
    "\n",
    "    def train(self, initial_environments, num_episodes, len_episodes):\n",
    "        \"\"\"\n",
    "        Run simulation to learn the q function\n",
    "        \"\"\"\n",
    "        \n",
    "        # Training loop\n",
    "        \n",
    "        for initial_environment in initial_environments:        \n",
    "        \n",
    "            for _ in range(num_episodes):\n",
    "                \n",
    "                environment = Environment(active_customers=initial_environment.get('active_customers'), \n",
    "                                    semi_active_customers=initial_environment.get('semi_active_customers'), \n",
    "                                    non_active_customers=initial_environment.get('non_active_customers'))\n",
    "                \n",
    "                for _ in range(len_episodes):\n",
    "                \n",
    "                    # Set the status from the environment status\n",
    "                    self._set_state(environment.export_status())\n",
    "                    # Choose an action\n",
    "                    action = self._select_action()\n",
    "                    # Step the environment, save the reward\n",
    "                    reward = environment.step(self._actions[action])\n",
    "                    # Save the new state\n",
    "                    new_state = self._tile_coding(environment.export_status())\n",
    "                    # Update the q function \n",
    "                    self._update_q_function(action, reward, new_state)\n",
    "\n",
    "\n",
    "    def get_value_function(self, export):\n",
    "        state = self._tile_coding(export)\n",
    "        q_values = self._q_function[state[0], state[1], state[2], :]\n",
    "        return np.mean(q_values)\n",
    "\n",
    "    def get_q_function(self, export):\n",
    "        state = self._tile_coding(export)\n",
    "        q_values = self._q_function[state[0], state[1], state[2] :]\n",
    "        return q_values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [None, 'email', 'coupon', 'resurrection', 'special']\n",
    "agent = VFA_Agent(actions, gamma=0.9, alpha=0.1, epsilon=0.1)\n",
    "\n",
    "initial_environments = [{'active_customers': 1500,\n",
    "                       'semi_active_customers': 1200,\n",
    "                       'non_active_customers': 2300}, \n",
    "                        {'active_customers': 2000,\n",
    "                       'semi_active_customers': 1500,\n",
    "                       'non_active_customers': 1000},\n",
    "                        {'active_customers': 1000,\n",
    "                       'semi_active_customers': 2300,\n",
    "                       'non_active_customers': 700},\n",
    "                        {'active_customers': 400,\n",
    "                       'semi_active_customers': 300,\n",
    "                       'non_active_customers': 4500},]\n",
    "\n",
    "\n",
    "\n",
    "agent.train(initial_environments=initial_environments, num_episodes=200, len_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14779.605555412174"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_environment = Environment(active_customers= 1500, semi_active_customers= 1200, non_active_customers= 2300)\n",
    "agent.get_value_function(my_environment.export_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 95177.33288297,   1965.5       , -10760.116206  ,  16947.51106147,\n",
       "       -29432.19996138])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_q_function(my_environment.export_status())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._q_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct LookAhead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLA_Agent():\n",
    "\n",
    "    def __init__(self, actions):\n",
    "\n",
    "        self._actions = actions\n",
    "        self._actions_dim = len(actions)\n",
    "\n",
    "        self._state = (0, 0, 0)\n",
    "\n",
    "        self._tile_coding_coef = 10\n",
    "\n",
    "        self._state_active_dim = 1000\n",
    "        self._state_semi_active_dim = 1000\n",
    "        self._state_non_active_dim = 1000\n",
    "\n",
    "        self._q_function = np.zeros([self._actions_dim])\n",
    "\n",
    "\n",
    "    def _tile_coding(self, export):\n",
    "        (num_active, num_semi_active, num_non_active) = export\n",
    "        return (int(num_active/self._tile_coding_coef), \n",
    "                       int(num_semi_active/self._tile_coding_coef), \n",
    "                       int(num_non_active/self._tile_coding_coef))\n",
    "\n",
    "\n",
    "    def _set_state(self, export):\n",
    "        self._state = self._tile_coding(export)\n",
    "\n",
    "        \n",
    "    def _select_action(self):\n",
    "        \"\"\"\n",
    "        Select best action using euristic policy\n",
    "        \"\"\"\n",
    "        return random.randint(0, self._actions_dim - 1)\n",
    "\n",
    "\n",
    "    def train(self, initial_environment, num_episodes, len_episodes):\n",
    "        \"\"\"\n",
    "        Run simulation to learn the q function\n",
    "        \"\"\"\n",
    "\n",
    "        # Loop on the action to be trained\n",
    "        for action_train in range(self._actions_dim): \n",
    "\n",
    "            rewards = []\n",
    "        \n",
    "            # Training loop\n",
    "            for _ in range(num_episodes):\n",
    "                \n",
    "                environment = Environment(active_customers=initial_environment.get('active_customers'), \n",
    "                                          semi_active_customers=initial_environment.get('semi_active_customers'), \n",
    "                                          non_active_customers=initial_environment.get('non_active_customers'))\n",
    "\n",
    "                for step in range(len_episodes):\n",
    "                \n",
    "                    # Set the status from the environment status\n",
    "                    self._set_state(environment.export_status())\n",
    "\n",
    "                    # Choose an action, if this is the first step, the use the action in training\n",
    "                    if step == 0:\n",
    "                        action = action_train\n",
    "                    else:\n",
    "                        action = self._select_action()\n",
    "\n",
    "                    # Step the environment, save the reward\n",
    "                    rewards.append( environment.step(self._actions[action]) )\n",
    "\n",
    "\n",
    "            self._q_function[action_train] = np.mean(rewards)\n",
    "\n",
    "\n",
    "    def get_value_function(self):\n",
    "        return self._q_function\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [None, 'email', 'coupon', 'resurrection', 'special']\n",
    "\n",
    "agent = DLA_Agent(actions)\n",
    "\n",
    "initial_environment = {'active_customers': 1500,\n",
    "                       'semi_active_customers': 1200,\n",
    "                       'non_active_customers': 2300,}\n",
    "\n",
    "\n",
    "\n",
    "agent.train(initial_environment=initial_environment, num_episodes=50, len_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17733.21 20324.73 17347.27 21250.93 13627.66]\n"
     ]
    }
   ],
   "source": [
    "print(agent.get_value_function())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surgeryschedulingunderuncertainty-XOZq-E-P-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
